<!-- 
- [UML클래스전략패턴](https://github.com/hyeonDD/fluent_python/blob/master/Part18/ex18-3/UML_class_diagram.png)
 -->
# 블로킹 호출을 에둘러 실행하기
Node.js의 창시자인 라이언 달은 '우리는 입출력을 완전히 잘못하고 있다'고 말하면서 그의 프로젝트 철학을 소개한다. 그는 **블로킹 함수**를 디스크나 네트워크 입출력의 수행으로 정의하면서, 이 함수들을 논블로킹 함수처럼 다루면 안 된다고 말한다. 이유를 설명하기 위해 그는 [표18-1]의 왼쪽 두 개의 열을 보여준다.

| 장치 | CPU 사이클 수 | 비례'체감'규모 |
| :--- | :--- | :--- |
| L1 캐시 | 3 | 3초 |
| L2 캐시 | 14 | 14초 |
| 램 | 250 | 250초 |
| 디스크 | 41,000,000 | 1.3년 |
| 네트워크 | 240,000,000 | 7.6년 |

표를 볼 때 최신 CPU는 GHz 대역의 클록으로 작동하므로 초당 수십억 개의 사이클을 실행한다는 점에 주의하라. 가령 CPU가 초당 10억 개의 사이클을 실행한다고 가정하자. 그 CPU는 1초에 L1 캐시는 333,333,333번 읽을 수 있고, 네트워크는 4번 읽을 수 있다. 표의 세 번째 열은 두 번째 열을 초 단위로 변환한 것이다. 따라서 사람이 느끼기에 L1 캐시를 읽는 데 3초가 걸린다면, 네트워크에서 읽는 데는 7.6년이 걸린다!

블로킹 함수가 전체 애플리케이션의 실행을 멈추지 않게 하는 두 가지 방법이 있다.

* 블로킹 연산을 각기 별도의 스레드에서 실행한다.
* 모든 블로킹 연산을 논블로킹 비동기 연산으로 바꾼다.

스레드는 제대로 작동하지만, 파이썬이 사용하는 OS 스레드는 (OS에 따라 다르지만) 각기 수메가바이트의 메모리를 사용한다. 수천 개의 연결을 처리해야 한다면 연결마다 하나의 스레드를 사용할 수 없다.

전통적으로 메모리 부담을 줄이기 위해 콜백으로 비동기 호출을 구현했다. 개념적으로 보면 하드웨어 인터럽트와 비슷한 저수준 개념이다. 응답을 기다리는 대신, 어떤 일이 발생할 때 호출될 함수를 등록한다. 이렇게 하면 우리가 호출한 것을 논블로킹으로 만들 수 있다. 라이언 달은 단순함과 저부하를 위해 콜백을 지지한다.

물론 우리가 만든 비동기 애플리케이션이 의존하는 이벤트 루프가 인터럽트, 스레드, 폴링, 백그라운드 프로세스 등을 이용해서 여러 동시성 요청이 진행되고 궁극적으로 완료될 수 있게 보장해주는 기반 구조를 사용할 수 있을 때만 콜백을 사용할 수 있다. 이벤트 루프가 응답을 받으면, 우리 코드를 다시 호출한다. 그러나 우리가 실수만 하지 않는다면 이벤트 루프와 우리 애플리케이션 코드가 공유하는 단일 스레드는 결코 블로킹되지 않는다.

코루틴으로 사용될 때 제너레이터는 비동기 프로그래밍을 할 수 있는 대안을 제시한다. 이벤트 루프의 관점에서 보면, 콜백을 호출하는 작업이나 중단된 코루틴의 send() 메서드를 호출하는 작업은 거의 같다. 중단된 코루틴마다 메모리 부하가 있기는 하지만, 스레드에 의한 부하보다는 비교할 수 없을 만큼 적다. 그리고 무시무시한 '콜백 지옥'도 없다. 콜백 지옥에 대해서는 18.5절 '콜백에서 Future와 코루틴으로'에서 다시 설명한다.

이제 flags_asyncio.py가 flags.py보다 5배나 빨리 실행되는 이유를 알 수 있을 것이다. flags.py는 이미지를 내려받을 때마다 수십억 CPU 사이클을 허비하기 때문이다. 실제로 CPU가 무언가 많은 일을 하지만, 우리가 만든 프로그램은 실행하지 않는다. 이와 반대로 flags_asyncio.py의 download_many() 함수가 loop_until+complete를 호출할 때, 이벤트 루프는 각각의 download_one() 코루틴을 첫 번째 yield from까지 구동시킨다. 이 yield from은 get_flag()의 첫 번째 yield from까지 구동시켜 aiohttp.request()를 호출한다. 이 과정에서 블로킹되는 부분이 없으므로 모든 요청이 아주 짧은 시간 안에 시작된다.

asyncio 기반 구조에서 첫 번째 응답을 받으면 이벤트 루프는 이것을 대기하고 있던 get_flag() 코루틴으로 전달한다. get_flag()가 응답을 받으면 다음번 yield from으로 넘어가서 resp.read()를 호출하고 제어권을 메인 루프로 넘긴다. 다른 요청도 거의 동시에 했기 때문에 각응답이 거의 동시에 도착한다. 각 get_flag()이 반환됨에 따라 대표 제너레이터인 download_one()이 실행을 재개해서 이미지 파일을 저장한다.
> 성능을 최대로 끌어올리려면 save_flag() 함수도 비동기식으로 구현해야 하지만, 아직 asyncio는 비동기 파일시스템 API를 제공하고 있지 않다. Node.js도 마찬가지다. 파일 저장이 애플리케이션에서 병목이 된다면 loop.run_in_executor() 함수 (http://bit.ly/1HGtQzc) 를 이용해서 스레드 풀 안에서 save_flag()를 실행하면 된다. 이 방법은[예제 18-9]에서 보여준다.

비동기 연산은 인터리브 방식으로 서로 엮여서 실행되므로, 많은 이미지를 내려받기 위해 필요한 전체 시간이 순차적으로 처리하는 경우보다 훨씬 짧아진다. asyncio로 600개의 HTTP 요청을 보냈을 때는 순차적으로 처리하는 경우보다 70배나 빨라졌다.

이제 HTTP 클라이언트 예제로 돌아가서 애니메이트되는 진행 막대를 보여주고 에러를 적절히 처리하는 방법을 알아보자.